[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "OTVision"
dynamic = ["version"]
authors = [
  { name="OpenTrafficCam contributors", email="team@opentrafficcam.org" },
  { name="platomo GmbH", email="info@platomo.de" },
]
description = "OTVision is a core module of the OpenTrafficCam framework to perform object detection and tracking."

readme = "README.md"
requires-python = "==3.12.*"
license = "GPL-3.0-only"
license-files = ["LICENSE"]
classifiers = [
    "Development Status :: 4 - Beta",
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
    "Operating System :: OS Independent",
]
keywords = ["OpenTrafficCam", "Traffic Analysis", "Traffic Counting", "Trajectories"]
dependencies = [
    "av==13.0.0",
    "coremltools==8.2; sys_platform == 'darwin'",
    "ffmpeg-python==0.2.0",
    "fire==0.7.0",
    "geopandas==1.0.1",
    "ijson==3.3.0",
    "more-itertools==10.7.0",
    "moviepy==1.0.3",
    "numpy==2.1.1; sys_platform != 'win32'",
    "numpy==1.26.4; sys_platform == 'win32'",
    "opencv-python-headless==4.10.0.84",
    "pandas==2.2.3",
    "PyYAML==6.0.2",
    "tqdm==4.67.1",
    "ujson==5.10.0",
]

[dependency-groups]
dev = [
    "black==25.1.0",
    "flake8==7.1.1",
    "interrogate==1.5.0",
    "isort==5.13.2",
    "jsonschema==4.23.0",
    "mypy==1.15.0",
    "pandas-stubs==2.2.3.250308",
    "pre-commit==3.8.0",
    "pytest==8.3.3",
    "pytest-cov==5.0.0",
    "twine==6.1.0",
    "yamllint==1.35.1",
]

[project.optional-dependencies]
inference_cpu = [
    "torch==2.7.1",
    "torchvision==0.22.1",
    "ultralytics==8.3.159",
]
inference_cuda = [
    "torch==2.7.1",
    "torchvision==0.22.1",
    "tensorrt==10.12.0.36; sys_platform != 'darwin'",
    "tensorrt-cu12-bindings==10.12.0.36; sys_platform != 'darwin'",
    "tensorrt-cu12-libs==10.12.0.36; sys_platform != 'darwin'",
    "ultralytics==8.3.159",
]
[project.urls]
Homepage = "https://opentrafficcam.org/"
Documentation = "https://opentrafficcam.org/overview/"
Repository = "https://github.com/OpenTrafficCam/OTVision"
Issues = "https://github.com/OpenTrafficCam/OTVision/issues"
Changelog = "https://github.com/OpenTrafficCam/OTVision/releases"


[tool.hatch.version]
path = "OTVision/version.py"

[tool.hatch.build.targets.wheel]
packages = ["OTVision"]

[tool.hatch.build]
directory = "dist"

[tool.black]
line-length = 88

[tool.isort]
profile = "black"

[tool.mypy]
ignore_missing_imports = true
ignore_missing_imports_per_module = true
disallow_untyped_defs = true

[[tool.mypy.overrides]]
module = "OTVision.view.*"
ignore_errors = true

[[tool.mypy.overrides]]
module = "OTVision.transform.*"
ignore_errors = true

[[tool.uv.dependency-metadata]]
name = "tensorrt-cu12"
requires-dist = ["tensorrt-cu12-bindings", "tensorrt-cu12-libs"]

[[tool.uv.dependency-metadata]]
name = "tensorrt-cu12-libs"
requires-dist = ["nvidia-cuda-runtime-cu12"]

[[tool.uv.dependency-metadata]]
name = "nvidia-cuda-runtime-cu12"

[[tool.uv.dependency-metadata]]
name = "tensorrt-cu12-bindings"

[[tool.uv.dependency-metadata]]
name = "tensorrt-cu12-libs"

[tool.uv]
environments = [
    "sys_platform == 'win32'",
    "sys_platform == 'darwin'",
    "sys_platform == 'linux'",
]
conflicts = [
    [
        { extra = "inference_cpu" },
        { extra = "inference_cuda" },
    ],
]


[tool.uv.sources]
torch = [
    { index = "pytorch-cu128", marker = "sys_platform != 'darwin'" , extra = "inference_cuda" },
    { index = "pytorch-cpu", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cpu", marker = "sys_platform == 'linux'", extra="inference_cpu" },
    { index = "pytorch-cpu", marker = "sys_platform == 'win32'", extra="inference_cpu" }
]
torchvision = [
    { index = "pytorch-cu128", marker = "sys_platform != 'darwin'" , extra = "inference_cuda" },
    { index = "pytorch-cpu", marker = "sys_platform == 'darwin'" },
    { index = "pytorch-cpu", marker = "sys_platform == 'linux'", extra="inference_cpu" },
    { index = "pytorch-cpu", marker = "sys_platform == 'win32'", extra="inference_cpu" }
]
tensorrt = { index = "tensorrt", extra = "inference_cuda" }
tensorrt-cu12-bindings = { index = "tensorrt", extra = "inference_cuda" }
tensorrt-cu12-libs = { index = "tensorrt", extra = "inference_cuda" }

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[[tool.uv.index]]
name = "tensorrt"
url = "https://pypi.nvidia.com/"
explicit = true
